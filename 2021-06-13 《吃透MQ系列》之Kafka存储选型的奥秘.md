---
title: Kafka存储选型的奥秘
date: 2021/6/13 20:46:25
categories: [技术干货]
tags: [kafka,消息队列,吃透系列]
---

从这篇文章开始，我将从微观角度切入，深入分析 Kafka 的设计原理。本文要讲的是 Kafka 最具代表性的：存储设计。

谈到 Kafka 的存储设计，了解不多的同学，可能会有这样的疑惑：为什么 Kafka 会采用 Logging（日志文件）这种很原始的方式来存储消息，而没考虑用数据库或者 KV 来做存储？而对 Kafka 有所了解的同学，应该能快速说出一些关键词：比如 Append Only、Linear Scans、磁盘顺序写、页缓存、零拷贝、稀疏索引、二分查找等等。

<!-- more -->

我计划写两篇文章，除了解释清楚上面的疑惑，同时还会给出一个脉络，帮助大家迅速切中 Kafka 存储设计的要点，然后将上面这些零散的知识点串联起来。此外，也希望大家在了解了 Kafka 的存储设计后，能对 Append Only Data Structures 这一经典的底层存储原理认识更加深刻，因为它驱动了业界太多极具影响力的存储系统走向成功，比如 HBase、Cassandra、RocksDB 等等。

# 1. Kafka的存储难点是什么？

为什么说存储设计是 Kafka 的精华所在？之前这篇文章做过分析，Kafka 通过简化消息模型，将自己退化成了一个海量消息的存储系统。

既然 Kafka 在功能特性上做了减法，必然会在存储上下功夫，做到其他 MQ 无法企及的性能表现。

但是在讲解 Kafka 的存储方案之前，我们很有必要思考下：为什么 Kafka 会采用 Logging（日志文件）的存储方式？它的选型依据到底是什么？

这也是本系列希望做到的，思考力胜过记忆力，多问 why，而不是死记 what。

谈到存储选型，Kafka 的决策逻辑我认为跟我们开发日常业务需求时的思路类似，到底是用 MySQL、Redis 还是其他存储方案？一定取决于具体的业务场景和需求。

我们试着从以下两个维度来分析下：

> 1、功能性需求：存的是什么数据？量级如何？需要存多久？CRUD 的场景都有哪些？
>
> 2、非功能需求：性能和稳定性的要求分别是什么样的？是否要考虑扩展性？

再回到 Kafka 来看，它的功能性需求至少包括以下几点：

**1、存的数据主要是消息流**：消息可以是最简单的文本字符串，也可以是自定义的复杂格式。

但是对于 Broker 来说，它只需处理好消息的投递即可，无需关注消息内容本身。

**2、数据量级非常大**：因为 Kafka 作为 Linkedin 的孵化项目诞生，一开始就用作实时日志流处理（运营活动中的埋点、运维监控指标等），按 Linkedin 当初的业务规模来看，每天要处理的消息量至少在千亿级规模。

**3、CRUD 场景足够简单：**因为消息队列最核心的功能就是数据管道，它仅提供转储能力，CRUD 操作确实很简单。

首先，消息等同于通知事件，都是追加写入的，根本无需考虑 update。其次，对于 Consumer 端来说，Broker 提供按 offset（消费位移）或者 timestamp（时间戳）查询消息的能力就行。再次，长时间未消费的消息（比如 7 天前的），Broker 做好定期删除即可。

接着，我们再来看看非功能性需求：

1、性能要求：之前的文章交代过，Linkedin 最初尝试过用 ActiveMQ 来解决数据传输问题，但是性能无法满足要求，然后才决定自研 Kafka。ActiveMQ 的单机吞吐量大约是万级 TPS，Kafka 显然要比 ActiveMQ 的性能高一个量级才行。

2、稳定性要求：消息的持久化（确保机器重启后历史数据不丢失）、单台 Broker 宕机后如何快速故障转移继续对外提供服务，这两个能力也是 Kafka 必须要考虑的。

3、扩展性要求：Kafka 面对的是海量数据的存储问题，必然要考虑存储的扩展性。

通过上面的需求分析，可知 Kafka 在存储选型时需要考虑以下两个方面：

> 1、功能性需求：其实足够简单，追加写、无需update、能根据消费位移和时间戳查询消息、能定期删除过期的消息。
>
> 2、非功能性需求：是挑战所在，因为 Kafka 本身就是一个高并发系统，必须会遇到高并发场景下典型的高性能、高可用和高扩展这 3 高挑战。

# 2. Kafka的存储选型分析

有了上面的需求梳理，我们继续往下分析。

首先声明下：我不是存储方面的专家，但是不妨碍我们去对比和思考：为什么 Kafka 最终会选用 logging（日志文件）来存储消息？

回到存储领域，下面几点常识是必须要提前了解的：

> 1、内存存取速度快，但容量小，价格昂贵，不适用长期要保存的数据。
>
> 2、磁盘存取速度相对较慢，但是廉价、而且可以持久化存储。
>
> 3、一次磁盘 IO 的耗时主要取决于：寻道时间和盘片旋转时间，提高磁盘 IO 性能最有效的方法就是减少随机 IO，增加顺序 IO。
>
> 4、磁盘的 IO 速度其实不一定比内存慢，取决于我们如何使用它。有非常多这方面的对比测试，结果表明：磁盘顺序写入速度可以达到几百兆/s，而随机写入速度只有几百KB/s，相差上千倍。此外，磁盘顺序 IO 访问是可以匹敌内存的随机 IO 访问性能的。



三类最具代表性的底层数据结构是：

1、以 B Tree 及其变种为代表，传统关系型数据库 MySQL、Oracle 的底层结构。

2、以 LSM Tree 为代表，众多 KV 存储系统比如 BigTable，HBase，Cassandra，RocksDB 的底层结构。



Kafka 的Logging存储选型最接近 LSM，是LSM 的极端情况，无内存。

Append Only、Linear Scans



确实如此，所以作者其中有个假设，就是写入远大于读取的时候，LSM是个很好的选择。我觉得更准确的描述应该是”优化了写，没有显著降低读“，因为大部分时候我们都是要求读最新的数据，而最新的数据很可能还在内存里面，即使不在内存里面，只要不是那些更新特别频繁的数据，其I/O次数也是有限的。所以LSM-Tree比较适合的应用场景是：insert数据量大，读数据量和update数据量不高且读一般针对最新数据。



类似 B-Tree 方案不合适的原因？插入性能不行，查询场景不复杂

内存方案不考虑？内存更昂贵，持久化能力



基准测试：
http://ifeve.com/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines/

推荐视频：
https://www.infoq.com/presentations/lsm-append-data-structures/

# 3. Kafka 的存储设计

为了解决存储的扩展性问题，有了 Partition（分片）。

Partition 底层又采用了 Logging 的存储方案。

为什么要分成 Segment？

Index  为什么用稀疏索引？而不是 Hash，而不是 BTree？

Topic -> Partition - > Segment -> index

为什么有了Partition还需要Segment？

https://www.zhihu.com/question/28925721



索引：

因为不是每条消息都创建相应的索引条目，所以索引条目是稀疏的；

索引的相对偏移量占据4个字节，而绝对偏移量占据8个字节，加上物理位置的4个字节，使用相对索引可以将每条索引条目的大小从12字节减少到8个字节；

因为偏移量有序的，再读取数据时，可以按照二分查找的方式去快速定位偏移量的位置；这样的稀疏索引是可以完全放到内存中，加快偏移量的查找。

# 4. 写在最后  

本文以 Partition 为切入点，从宏观角度解析了 Kafka 的整体架构，再简单总结下本文的内容：

1、Kafka 通过巧妙的模型设计，将自己退化成一个海量消息的存储系统。

2、为了解决存储的扩展性问题，Kafka 对数据进行了水平拆分，引出了 Partition（分区），这是 Kafka 部署的基本单元，同时也是 Kafka 并发处理的最小粒度。

3、对于一个高并发系统来说，还需要做到高可用，Kafka 通过 Partition 的多副本冗余机制进行故障转移，确保了高可靠。

希望这篇文章能让大家摆脱死记硬背的模式，先找到一个支点，再去推敲 Kafka 架构设计的来龙去脉，知其所以然。

下篇文章将从微观角度切入，深入分析 Kafka 的设计原理，我们下期见！