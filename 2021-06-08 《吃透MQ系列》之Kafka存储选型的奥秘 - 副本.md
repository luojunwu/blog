大家好，我是武哥。这是《吃透 MQ 系列》之 Kafka 的第 3 篇，错过前两篇文章的，建议再温习下：

[**扒开 Kafka 的神秘面纱**](http://mp.weixin.qq.com/s?__biz=MzU2MTM4NDAwMw==&mid=2247490102&idx=1&sn=68d55b3c5ac74038c76d6837b862a11c&chksm=fc78c51acb0f4c0cd5a1d6ceedb9948f82d48791ab789e9edfd6e83e34fbad1ace5749bee203&scene=21#wechat_redirect)

**Kafka 架构设计的任督二脉**

从这篇文章开始，我将从微观角度切入，深入分析 Kafka 的设计原理。本文要讲的是 Kafka 最精髓的：存储设计。

谈到 Kafka 的存储设计，了解不多的同学，可能会有这样的疑惑：为什么 Kafka 会采用 Logging（日志文件）这种很原始的方式来存储消息，而没考虑用数据库或者 KV 来做存储？

而对 Kafka 有所了解的同学，应该能快速说出一些关键词：比如 Append Only、Linear Scans、磁盘顺序写、页缓存、零拷贝、稀疏索引、二分查找等等。

这篇文章，我希望除了解释清楚上面的疑惑，同时还能找到一个脉络，帮助大家将这些零散的知识点串联起来。

此外，也希望大家在了解了 Kafka 的存储设计后，能对 Append Only Data Structure 这一经典的底层存储原理认识更加深刻，因为它驱动了业界太多极具影响力的存储系统走向成功，比如 HBase、Cassandra、RocksDB 等等。

# 1. Kafka的存储难点是什么？

为什么说存储设计是 Kafka 的精华所在？这篇文章做过分析，Kafka 通过简化消息模型，将自己退化成了一个海量消息的存储系统，既然 Kafka 在功能特性上做了减法，必然会在存储上下功夫，做到其他 MQ 无法企及的性能表现。



但是在讲解 Kafka 的存储方案之前，我们很有必要思考下：为什么 Kafka 会采用 Logging（日志文件）的存储方式？它的选型依据到底是什么？如果换作是你 ，你又会怎么选？

这个决策逻辑我认为跟我们开发日常业务需求时，到底是用 MySQL、Redis 还是其他的存储方式？思路其实是类似的，存储选型取决于具体的业务场景和需求。

我们可以试着从以下两个维度来分析下：

1、功能性需求：存的是什么数据？量级如何？需要存多久？CRUD 的场景都有哪些？

2、非功能需求：性能和稳定性的要求分别是什么样的？是否要考虑扩展性？

再回到 Kafka 来看，它的功能性需求至少包括以下几点：

1、存的数据主要是消息流：消息可以是最简单的文本字符串，也可以是自定义的复杂格式。但是对于 Broker 来说，它只需处理好消息的投递即可，无需关注消息内容本身。

2、数据量级非常大：因为 Kafka 作为 Linkedin 的孵化项目诞生，一开始就用作实时日志流处理（运营活动中的埋点、运维监控指标等），按 Linkedin 当初的业务规模来看，每天要处理的消息量至少在千亿级规模。

3、CRUD 场景足够简单：因为消息队列最核心的功能就是数据管道，它仅提供转储能力，因此有别于其他业务场景，CRUD 确实足够简单。首先，消息的性质等同于通知事件（event），都是追加写入的，根本无需考虑 update。对于 consumer 端来说，broker 提供按 offset（消费位移）或者 timestamp（时间戳）查询消息的能力即可，没有更复杂的查询场景了。长时间未消费的消息（比如 7 天前的消息），broker 做定期删除即可。

再来看看非功能性需求：

1、性能要求：之前的文章交代过，Linkedin 最初尝试过用 ActiveMQ 来解决数据传输问题，但是性能无法满足要求，然后才决定自研 Kafka。ActiveMQ 的单机吞吐量大约是万级 TPS，Kafka 显然要比 ActiveMQ 的性能高一个量级才行。

2、稳定性要求：消息的持久化（确保机器重启后历史数据不丢失）、单台 Broker 宕机后如何快速故障转移继续对外提供正常服务，这两个能力也是 Kafka 必须要考虑的。

3、扩展性要求：Kafka 面对的是海量数据的存储问题，必然要考虑存储的扩展性。

# 2. Kafka的存储选型分析

通过上一节的存储需求分析，可知 Kafka 本身就是一个高并发系统，必须会遇到高并发场景下典型的三高挑战：高性能、高可用和高扩展，而功能需求其实足够简单：追加写、无需update、能根据消费位移和时间戳查询消息、能定期删除过期的消息。

现在，我们再回过头来思考 Kafka 的存储选型。先提前说明下：我不是存储方案的专家，下面这个章节的内容都是我的个人思考，因为我我觉得搞懂 why，会比单纯去记住 what 更加重要。

回到存储领域，这几点常识是必须要先了解的：

1、内存存取速度快，但容量小，价格昂贵，不适用于长期保存的数据。

2、磁盘存取速度相对较慢，但是廉价而且可以持久化存储。

3、一次磁盘 IO 的耗时主要取决于寻道时间和盘片旋转时间，提高磁盘 IO 性能最有效的方法就是减少磁盘随机 IO。



三类最具代表性的底层数据结构是：

1、以 B Tree 及其变种为代表，传统关系型数据库 MySQL、Oracle 的底层结构。

2、以 LSM Tree 为代表，众多 KV 存储系统比如 BigTable，HBase，Cassandra，RocksDB 的底层结构。



类似 B-Tree 方案不合适的原因？插入性能不行，查询场景不复杂

内存方案不考虑？内存更昂贵，持久化能力



基准测试：
http://ifeve.com/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines/

推荐视频：
https://www.infoq.com/presentations/lsm-append-data-structures/

# 2. Kafka 的存储方案

Topic -> Partition - > Segment -> index

为什么有了Partition还需要Segment？

https://www.zhihu.com/question/28925721



索引：

因为不是每条消息都创建相应的索引条目，所以索引条目是稀疏的；

索引的相对偏移量占据4个字节，而绝对偏移量占据8个字节，加上物理位置的4个字节，使用相对索引可以将每条索引条目的大小从12字节减少到8个字节；

因为偏移量有序的，再读取数据时，可以按照二分查找的方式去快速定位偏移量的位置；这样的稀疏索引是可以完全放到内存中，加快偏移量的查找。



# 3.Kafka 是如何优化存取数据性能的？

1、发送数据：分批次、压缩（充分利用consumer端，分摊压力；压缩提高数据传输效率 ）；高吞吐、低延迟解释

2、存数据：Page Cache（充分利用磁盘特性，异步刷盘），log segment并非用到了mmap

3、消费数据：并非完全意义上的顺序读，index文件使用了mmap，sendfile

而在consumer端，如果消费的数据是最近刚刚生产的，那么它们有很大概率依然在page cache中，所以Kafka源码中的FileChannel.transferTo 直接调用底层 sendfile 实现Zero copy，将数据直接从page cache传输到socket buffer然后再通过网络传给consumer——这是consumer高TPS的原因之一。

# 4. 写在最后  

本文以 Partition 为切入点，从宏观角度解析了 Kafka 的整体架构，再简单总结下本文的内容：

1、Kafka 通过巧妙的模型设计，将自己退化成一个海量消息的存储系统。

2、为了解决存储的扩展性问题，Kafka 对数据进行了水平拆分，引出了 Partition（分区），这是 Kafka 部署的基本单元，同时也是 Kafka 并发处理的最小粒度。

3、对于一个高并发系统来说，还需要做到高可用，Kafka 通过 Partition 的多副本冗余机制进行故障转移，确保了高可靠。

希望这篇文章能让大家摆脱死记硬背的模式，先找到一个支点，再去推敲 Kafka 架构设计的来龙去脉，知其所以然。

下篇文章将从微观角度切入，深入分析 Kafka 的设计原理，我们下期见！